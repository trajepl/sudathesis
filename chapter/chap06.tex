\chapter{总结与展望}
\label{chap:chap07}

\section{全文总结}

所谓词语间语义关联度计算，是指对于给定的一对词语，研究者们采用合适的方法，结合不同的背景知识，给出一个数值来表示两个词语在语义空间上的关联程度。这是一项基础且十分重要的任务，在自然语言处理、推荐系统和计算机视觉方面都有相关的应用。经典的计算方法主要利用了隐含在词典库（WordNet）或文本语料（Wikipedia）中的隐含语义关系，他们或在词典树上基于距离关系，或在Wikipedia中基于共现原则来衡量两个词之间的相似程度，取得了不错的效果。然而这些方法忽略了隐含在词语背后的语义网络，近年来，新提出的基于自由关联网络的方法改善了这个缺点，在语义关联度计算方面取得了更好的效果。但是这种方法需要事先对Wikipedia进行大量的复杂的预处理，此外，这种方法采用了固定的评分函数来衡量Wikipedia页面之间的相关性，这造成了模型灵活性和表达能力的欠缺。因此，本文提出知识关联网络来学习更加灵活鲁棒的知识表示，由此改良语义关联度计算的表现，具体来讲，本文的贡献包含下面几个部分。
\begin{enumerate}[（1）]
    \item 本文基于WordNet、DBpedia知识库去构建了知识关联网络，同时考虑了词语与词语、词语与实体以及实体与实体之间的关系对语义关联度度量的影响。
    \item 在知识关联网络的实体层，针对不同的网络结构，本文提出了不同的网络嵌入模型。在基于WordNet构建的网络中，本文将图注意力机制应用到无监督表示学习中；在基于DBpedia构建的网络中，本文同时考虑了实体属性空间与拓扑空间的语义信息。这些分布式向量表示方法在扩展性与灵活性上要明显优于传统模型中的基于规则的比较函数。
    \item 基于标准语义关联度度量数据集的实验证明，本文的模型要优于几种对比模型，取得了更好的效果。
\end{enumerate}

\section{工作展望}
本文对于知识关联网络驱动语义关联度计算进行了深入的研究，针对不同的知识库，本文采用不同的模型来学习实体向量表征，取得了不错的效果。但是本文的工作仍然有需要改进的地方：
\begin{enumerate}[（1）]
    \item 本文通过网络嵌入方法将词语背后关联的实体语义信息转化为分布式向量，可以起到丰富词语语义特征的作用。但是对于自然语言处理的其他任务，比如文本分类、关键词抽取等任务，添加词语背后的语义特征是否起作用仍需要实验验证。
    \item 在基于WordNet构建的知识关联网络中，本文采用的基于自注意力机制的无监督学习虽然取得了不错的效果，但是网络嵌入过程相比传统的node2vec模型训练过程比较慢，无法迁移到大规模图上。在未来的工作中，我们将考虑对大规模图上的嵌入方法进行深入研究。
    \item 在基于DBpedia构建的知识关联网络中，对于一个给定的单词，跟其相关度比较高的的往往只有几个实体，大部分实体只是简单的包含该单词，这部分实体构成噪音实体。在未来的工作中，我们考察采用实体背后所对应的抽象分类（Category）图来减少图的规模，提高词语关联度比较的速度与性能。
\end{enumerate}